{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK and the Basics - Example: Informative Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw looking into list of most common and uncommon words in case of alice in wonderland did NOT provide any good insight in the book.\n",
    "\n",
    "**Here we plan to find IMPORTANT and DESCRIPTIVE words automatically**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File ids of of project gutenberg that came when we downloaded nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Alice in Wonderland\n",
    "alice = nltk.corpus.gutenberg.words(\"carroll-alice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of the words in alice in wonderland\n",
    "alice_fd = nltk.FreqDist(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the 100 most common words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 1993), (\"'\", 1731), ('the', 1527), ('and', 802), ('.', 764), ('to', 725), ('a', 615), ('I', 543), ('it', 527), ('she', 509), ('of', 500), ('said', 456), (\",'\", 397), ('Alice', 396), ('in', 357), ('was', 352), ('you', 345), (\"!'\", 278), ('that', 275), ('as', 246), ('her', 243), (':', 216), ('t', 216), ('at', 202), ('s', 195), ('on', 189), (\".'\", 187), (';', 186), ('had', 177), ('with', 175), ('all', 173), ('!', 155), (\"?'\", 154), ('be', 145), ('-', 141), ('for', 140), ('--', 140), ('but', 133), ('not', 129), ('they', 129), ('very', 126), ('little', 125), ('so', 124), ('out', 116), ('this', 113), ('The', 108), ('he', 101), ('down', 99), ('up', 98), ('is', 97), ('about', 94), ('one', 94), ('his', 94), ('what', 93), ('them', 88), ('know', 87), ('were', 85), ('like', 84), ('went', 83), ('again', 83), ('herself', 83), ('if', 78), ('or', 76), ('thought', 74), ('Queen', 74), ('could', 73), ('have', 73), ('then', 72), ('would', 70), ('no', 69), ('when', 69), ('do', 68), ('time', 68), ('into', 67), ('And', 67), ('see', 66), ('there', 65), ('It', 64), ('off', 62), ('me', 61), ('King', 61), ('did', 60), ('*', 60), ('Turtle', 59), ('began', 58), ('m', 58), ('can', 57), ('way', 56), ('ll', 56), ('its', 56), ('Mock', 56), ('by', 55), ('my', 55), ('Hatter', 55), ('Gryphon', 55), ('quite', 53), ('your', 53), ('an', 52), ('much', 51), ('say', 51)]\n"
     ]
    }
   ],
   "source": [
    "alice_fd_100 = alice_fd.most_common(100)\n",
    "print(alice_fd_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can do the same for another book. We can assume they will have a lot on NON-DESCRIPTIVE words if we substract the 2 lists from one another. Then the leftover will be the common words that are unique to the book it came from.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024), ('a', 4569), ('to', 4542), (';', 4072), ('in', 3916), ('that', 2982), (\"'\", 2684), ('-', 2552), ('his', 2459), ('it', 2209), ('I', 2124), ('s', 1739), ('is', 1695), ('he', 1661), ('with', 1659), ('was', 1632), ('as', 1620), ('\"', 1478), ('all', 1462), ('for', 1414), ('this', 1280), ('!', 1269), ('at', 1231), ('by', 1137), ('but', 1113), ('not', 1103), ('--', 1070), ('him', 1058), ('from', 1052), ('be', 1030), ('on', 1005), ('so', 918), ('whale', 906), ('one', 889), ('you', 841), ('had', 767), ('have', 760), ('there', 715), ('But', 705), ('or', 697), ('were', 680), ('now', 646), ('which', 640), ('?', 637), ('me', 627), ('like', 624), ('The', 612), ('their', 612), ('are', 586), ('they', 586), ('an', 582), ('some', 578), ('then', 571), ('my', 564), ('when', 553), ('upon', 538), ('out', 529), ('into', 520), ('man', 508), ('ship', 507), ('up', 505), ('more', 501), ('Ahab', 501), ('.\"', 489), ('no', 484), ('them', 471), ('ye', 460), ('what', 442), ('old', 436), ('sea', 433), ('would', 421), ('if', 421), ('been', 415), ('we', 413), ('other', 412), ('over', 403), ('these', 381), ('will', 379), ('its', 372), ('And', 369), ('down', 364), ('only', 360), ('such', 336), ('head', 335), ('though', 335), ('boat', 330), ('her', 329), ('time', 324), ('any', 320), ('who', 319), ('long', 318), ('very', 311), ('It', 310), ('than', 309), ('!\"', 305), ('about', 304)]\n"
     ]
    }
   ],
   "source": [
    "moby = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")\n",
    "moby_fd = nltk.FreqDist(moby)\n",
    "moby_fd_100 = moby_fd.most_common(100)\n",
    "print(moby_fd_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have the 100 most common words from each book. We no longer care exactly how many times each word was seen and thus can drop the count/frequency of these words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The', 612)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50th most common word from moby dick book\n",
    "moby_50 = moby_fd_100[50]\n",
    "moby_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the first element will give the word and drop the number\n",
    "moby_50[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', \"'\", 'the', 'and', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_100  = [word[0] for word in alice_fd_100]\n",
    "moby_100 = [word[0] for word in moby_fd_100]\n",
    "alice_100[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can substract the sets (unique words of each variable) of the variables. Two sets can be subtracted from one another leaving us with the difference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'can',\n",
       " '*',\n",
       " 'say',\n",
       " 'know',\n",
       " 'began',\n",
       " 'herself',\n",
       " 'she',\n",
       " 'off',\n",
       " 'again',\n",
       " 'did',\n",
       " 'see',\n",
       " 'quite',\n",
       " 'Alice',\n",
       " 'little',\n",
       " 'Hatter',\n",
       " \".'\",\n",
       " 'much',\n",
       " 'went',\n",
       " 'Gryphon',\n",
       " 'Queen',\n",
       " \"?'\",\n",
       " 'could',\n",
       " 'way',\n",
       " 'thought',\n",
       " 'said',\n",
       " 'do',\n",
       " \"!'\",\n",
       " ':',\n",
       " 'King',\n",
       " 'your',\n",
       " 'Mock',\n",
       " 'Turtle',\n",
       " \",'\",\n",
       " 'm',\n",
       " 'll']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(alice_100) - set(moby_100))\n",
    "# set(alice_100) - set(moby_100) will give a dictionary \n",
    "# we converted it to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 100 most common words in alice in winderland substracting 100 most common words of Moby dick, we are left with relatively descriptive words (more so than most common and uncommon words)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sea',\n",
       " '.\"',\n",
       " 'these',\n",
       " '?',\n",
       " 'only',\n",
       " 'are',\n",
       " 'upon',\n",
       " 'Ahab',\n",
       " 'been',\n",
       " 'which',\n",
       " 'man',\n",
       " 'him',\n",
       " 'will',\n",
       " 'whale',\n",
       " 'head',\n",
       " 'ship',\n",
       " 'old',\n",
       " 'boat',\n",
       " 'though',\n",
       " 'some',\n",
       " 'such',\n",
       " 'over',\n",
       " 'long',\n",
       " 'who',\n",
       " 'we',\n",
       " 'But',\n",
       " 'than',\n",
       " 'more',\n",
       " 'from',\n",
       " 'other',\n",
       " 'ye',\n",
       " '!\"',\n",
       " 'any',\n",
       " '\"',\n",
       " 'now',\n",
       " 'their']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(moby_100) - set(alice_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This method is super elementary. Later we will work on `Term Frequency Inverse document frequency` will give accurate result.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
