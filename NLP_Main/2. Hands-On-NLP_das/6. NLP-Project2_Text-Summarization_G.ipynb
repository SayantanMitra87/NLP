{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT SUMMARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will fetch data from online sources such as wikipedia. Then we will parse those articles and convert them into strings. Then we will summarize each article (which might be 3-4 pages long) into 4-5 sentences.\n",
    "\n",
    "It can be done by \n",
    "1. Simple NLP approach and \n",
    "2. A more complex deep NLP approach. \n",
    "\n",
    "We will be looking into Simple NLP approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action plan**<br/>\n",
    "Here we have to atfirst tokenize an article into sentences. Then preprocess. Then prepare histogram (that will contain counts for each word in sentences of the article). Then we have to make weighted histogram i.e. every word in a sentence will have a weight. Then based on the weight of the words, each sentence will have a score(depending on the words present in the sentence). Then based on the score of the sentences in the article, we can select top 2-3 sentences as the summary of entire article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sayantan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Global warming - Wikipedia</title>\\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\\\s)client-nojs(\\\\s|$)/, \"$1client-js$2\" );</script>\\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Global_warming\",\"wgTitle\":\"Global warming\",\"wgCurRevisionId\":870505915,\"wgRevisionId\":870505915,\"wgArticleId\":5042951,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"CS1 maint: Uses authors parameter\",\"CS1 maint: Explicit use of et al.\",\"Webarchive template wayback links\",\"CS1: Julian\\xe2\\x80\\x93Gregorian uncertainty\",\"Pages containing links to subscription-only content\",\"CS1 maint: Multiple names: authors list\",\"Webarchive template other archives\",\"Wikipedia indefinitely semi-protected pages\",'\n"
     ]
    }
   ],
   "source": [
    "# Text Summarization using NLP\n",
    "# Install BeautifulSoup 4 - pip install beautifulsoup4\n",
    "# Install lxml - pip install lxml\n",
    "\n",
    "# Importing the libraries\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Gettings the data source that needs to be summarized\n",
    "source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Global_warming').read()\n",
    "print(source[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fetch the articles from wikipedia, we need to scrape wikipedia. And for that we need `beautifulsoup4` and `lxml`.\n",
    "\n",
    "`lxml` is a type of parser that beautiful soup uses to parse a HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the data/ creating BeautifulSoup object\n",
    "soup = bs.BeautifulSoup(source,'lxml') \n",
    "#print(soup) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soup is more visible than what we got from original HTML. But still a lot of cleaning needs to be done to just get the string part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nGlobal warming is a long-term rise in the average temperature of the Earth's climate system, an aspect of climate change shown by temperature measurements and by multiple effects of the warming.[2][3] The term commonly refers to the mainly human-caused observed warming since pre-industrial times and its projected continuation,[4] though there were also much earlier periods of global warming.[5] In the modern context the terms are commonly used interchangeably,[6] but global warming more specifically relates to worldwide surface temperature increases; while climate change is any regional or global statistically identifiable persistent change in the state of climate which lasts for decades or longer, including warming or cooling.[7][8] Many of the observed warming changes since the 1950s are unprecedented in the instrumental temperature record, and in historical and paleoclimate proxy records of climate change over thousands to millions of years.[2]\\nIn 2013, the Intergovernmental Pane\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the data\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text # to extract only the text part of the paragraph\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p` is the paragraph tag in the HTML. In wikipedia all the text is within `paragraph` tag and thats why we will be using `p` tag to select the text part of wikipedia article and adding it to `text` variable. [Some sites also put the articles within `div` tag or `span` tag. Thus we might have to change this based on which website we are fetching the data]\n",
    "\n",
    "After selecting only the text part based on `p` tag we still see some unrequired part in the string. Thus, we need to preprocess these part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Global warming is a long-term rise in the average temperature of the Earth's climate system, an aspect of climate change shown by temperature measurements and by multiple effects of the warming. The term commonly refers to the mainly human-caused observed warming since pre-industrial times and its projected continuation, though there were also much earlier periods of global warming. In the modern context the terms are commonly used interchangeably, but global warming more specifically relates to worldwide surface temperature increases; while climate change is any regional or global statistically identifiable persistent change in the state of climate which lasts for decades or longer, including warming or cooling. Many of the observed warming changes since the 1950s are unprecedented in the instrumental temperature record, and in historical and paleoclimate proxy records of climate change over thousands to millions of years. In 2013, the Intergovernmental Panel on Climate Change (IPCC)\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data_1\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text) # to replace the reference with a single space\n",
    "text = re.sub(r'\\s+',' ',text) # remove extra spaces\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' global warming is a long term rise in the average temperature of the earth s climate system an aspect of climate change shown by temperature measurements and by multiple effects of the warming the term commonly refers to the mainly human caused observed warming since pre industrial times and its projected continuation though there were also much earlier periods of global warming in the modern context the terms are commonly used interchangeably but global warming more specifically relates to worldwide surface temperature increases while climate change is any regional or global statistically identifiable persistent change in the state of climate which lasts for decades or longer including warming or cooling many of the observed warming changes since the s are unprecedented in the instrumental temperature record and in historical and paleoclimate proxy records of climate change over thousands to millions of years in the intergovernmental panel on climate change ipcc fifth assessment repo'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data_2\n",
    "clean_text = text.lower()\n",
    "clean_text = re.sub(r'\\W',' ',clean_text) # remove non-word characters\n",
    "clean_text = re.sub(r'\\d',' ',clean_text) # remove digits\n",
    "clean_text = re.sub(r'\\s+',' ',clean_text) # remove extra spaces\n",
    "clean_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built `clean_text` and `text` both. We will built the word histogram based on `clean_text` and not `text` because `text` contains a lot of unnecessary stuff including punctuations digits etc. \n",
    "\n",
    "But once summarized output we might need some digits like 30 degree centigrade as it is a global warming article. Thus, digits can be important in the summary sentence but not for word histogram. So we are going to do histogram on the `clean_text` and summary on the `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" Global warming is a long-term rise in the average temperature of the Earth's climate system, an aspect of climate change shown by temperature measurements and by multiple effects of the warming.\", 'The term commonly refers to the mainly human-caused observed warming since pre-industrial times and its projected continuation, though there were also much earlier periods of global warming.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize sentences because we want to find most meaningful sentences\n",
    "sentences = nltk.sent_tokenize(text) # clean_text do NOT contain period so sent_tokenize won't word\n",
    "print(sentences[:2])\n",
    "# Stopword list\n",
    "stop_words = nltk.corpus.stopwords.words('english') \n",
    "# need to remove stopwords from word histograms to have only impactful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('global', 75), ('warming', 83), ('long', 8), ('term', 11), ('rise', 8)]\n"
     ]
    }
   ],
   "source": [
    "# Word counts: [word histogram]\n",
    "word2count = {} # will contain word histogram\n",
    "\n",
    "for word in nltk.word_tokenize(clean_text): # we need clean_text as it only contains words\n",
    "     if word not in stop_words: # ignore stopwords present in the article\n",
    "        if word not in word2count.keys(): # count the impactful words\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1   \n",
    "\n",
    "print(list(word2count.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('global', 0.8064516129032258), ('warming', 0.8924731182795699), ('long', 0.08602150537634409), ('term', 0.11827956989247312), ('rise', 0.08602150537634409)]\n"
     ]
    }
   ],
   "source": [
    "# Converting counts to weights: [weighted histogram]\n",
    "for key in word2count.keys():\n",
    "    word2count[key] = word2count[key]/max(word2count.values())\n",
    "\n",
    "print(list(word2count.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`word2count[key]` is the count value of a particular word or key. We have to divide the count value with maximum count value of the entire `word2count` dictionary, to build weighted histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The largest human influence has been the emission of greenhouse gases such as carbon dioxide, methane, and nitrous oxide.', 3.5196808510638293), ('In view of the dominant role of human activity in causing it, the phenomenon is sometimes called \"anthropogenic global warming\" or \"anthropogenic climate change\".', 5.169669412033858)]\n"
     ]
    }
   ],
   "source": [
    "# Produce sentence scores    \n",
    "sent2score = {}\n",
    "for sentence in sentences:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in word2count.keys():\n",
    "            if len(sentence.split(' ')) < 25: #\n",
    "                if sentence not in sent2score.keys():\n",
    "                    sent2score[sentence] = word2count[word]\n",
    "                else:\n",
    "                    sent2score[sentence] += word2count[word]\n",
    "    \n",
    "print(list(sent2score.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code explanation**\n",
    " * `for word in nltk.word_tokenize(sentence.lower()):` - sentence was made from `text` so we need to lower it\n",
    " \n",
    " * if a word from the sentence is present in `word2count` dictionary, then we check whether the sentence (that contains this word) is present in the `sent2score` dictionary or not? If not, we place the sentence as a key and the weighted value of the word as its value. If it is already present, we will keep on adding the weighted value of the word.\n",
    " \n",
    " * `if len(sentence.split(' ')) < 25:`- Some sentences might NOT be important, but they might be very long. Longer sentence can get a higher value. So we are excluding sentences that are longer than 25 words, to avoid this from happening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "In 1986 and November 1987, NASA climate scientist James Hansen gave testimony to Congress on global warming.\n",
      "In the late 19th century, scientists first argued that human emissions of greenhouse gases could change the climate.\n",
      "The phrase began to come into common use, and in 1976 Mikhail Budyko's statement that \"a global warming up has started\" was widely reported.\n",
      "Global oil companies have begun to acknowledge climate change exists and is caused by human activities and the burning of fossil fuels.\n",
      "Adaptation is especially important in developing countries since those countries are predicted to bear the brunt of the effects of global warming.\n",
      "---------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Gettings best 5 lines    \n",
    "import heapq\n",
    "best_sentences = heapq.nlargest(5, sent2score, key=sent2score.get)\n",
    "\n",
    "print('-'*117)\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)\n",
    "print('-'*117)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
